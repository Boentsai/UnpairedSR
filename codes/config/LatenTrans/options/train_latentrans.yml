#### general settings
name: latentrans
use_tb_logger: false
model: LatenTransModel
scale: 4
gpu_ids: [5]
metrics: [psnr, ssim]

#### datasets
datasets:
  train:
    name: DIV2K
    mode: UnPairedDataset
    data_type: lmdb
    color: RGB
    ratio: 1

    dataroot_tgt: /mnt/hdd/lzx/SRDatasets/NTIRE2020/train_HR_half.lmdb
    dataroot_src: /mnt/hdd/lzx/SRDatasets/NTIRE2017/trainx4_half.lmdb

    use_shuffle: true
    n_workers: 4  # per GPU
    batch_size: 32
    tgt_size: 128
    src_size: 32
    use_flip: true
    use_rot: true

  val:
    name: 2017Track2_mini
    mode: PairedDataset
    data_type: lmdb
    color: RGB

    dataroot_src: /mnt/hdd/lzx/SRDatasets/NTIRE2017/validx4_mini.lmdb
    dataroot_tgt: /mnt/hdd/lzx/SRDatasets/DIV2K_valid/HR/x4_mini.lmdb

#### network structures
Encoder:
  which_network: Encoder
  setting:
    nf: 64
    nb: 8
    scale_factor: 4
  pretrain: 
    path: ../../../checkpoints/AutoEncoder/encoderx4_8b16b.pth
    strict_load: true

Decoder:
  which_network: Decoder
  setting:
    nf: 64
    nb: 16
    scale_factor: 4
  pretrain: 
    path: ../../../checkpoints/AutoEncoder/decoderx4_8b16b.pth
  
#### network structures  
netG1:
  which_network: Translator
  setting:
    nf: 64
    nb: 8
    scale: 1
  pretrain: 
    path: ~
    strict_load: true

netD1:
  which_network: PatchGANDiscriminator
  setting:
    in_c: 3
    nf: 64
    nb: 3
    stride: 1
  pretrain: 
    path: ~
    strict_load: true

netG2:
  which_network: Translator
  setting:
    nf: 64
    nb: 8
    zero_tail: true
    scale: 0.25
  pretrain: 
    path: ~
    strict_load: true

netD2:
  which_network: PatchGANDiscriminator
  setting:
    in_c: 3
    nf: 64
    nb: 3
    stride: 1
  pretrain: 
    path: ~
    strict_load: true

#### training settings: learning rate scheme, loss
train:
  resume_state: ~

  losses:
    sr_adv:
      type: GANLoss
      gan_type: lsgan
      real_label_val: 1.0
      fake_label_val: 0.0
      weight: !!float 1.0
    
    lr_adv:
      type: GANLoss
      gan_type: lsgan
      real_label_val: 1.0
      fake_label_val: 0.0
      weight: !!float 1.0

    cycle: 
      type: L1Loss
      weight: 1.0

  optimizers:
    netG1:
      type: Adam
      lr: !!float 1e-4
    netG2:
      type: Adam
      lr: !!float 1e-4
    netD1:
      type: Adam
      lr: !!float 1e-4
    netD2:
      type: Adam
      lr: !!float 1e-4
   
  niter: 100000
  warmup_iter: -1  # no warm up

  scheduler:
    type: MultiStepLR
    milestones: [50000]
    gamma: 0.5

  manual_seed: 0
  val_freq: !!float 5e3

#### logger
logger:
  print_freq: 100
  save_checkpoint_freq: !!float 5e3
