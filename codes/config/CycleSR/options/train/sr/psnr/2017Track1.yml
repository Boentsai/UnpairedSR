#### general settings
name: CycleSR2017Track1
use_tb_logger: false
model: CycleSRModel
scale: 4
gpu_ids: [3]
metrics: [psnr, ssim, lpips]

#### datasets
datasets:
  train:
    name: DIV2K
    mode: PairedRefDataset
    data_type: lmdb
    color: RGB
    ratios: [1, 1]

    dataroot_ref_tgt: /home/lzx/SRDatasets/DIV2K_train/HR/x4_half.lmdb
    dataroot_ref_src: /home/lzx/SRDatasets/DIV2K_train/BicLR/x4_half.lmdb
    dataroot_src: /home/lzx/SRDatasets/NTIRE2017/train_LR/x4_half.lmdb

    use_shuffle: true
    workers_per_gpu: 8  # per GPU
    imgs_per_gpu: 32
    tgt_size: 128
    src_size: 32
    use_flip: true
    use_rot: true

  val:
    name: 2017Track1_mini
    mode: PairedDataset
    data_type: lmdb
    color: RGB

    dataroot_src: /home/lzx/SRDatasets/NTIRE2017/valid_LR/x4_mini.lmdb
    dataroot_tgt: /home/lzx/SRDatasets/DIV2K_valid/HR/x4_mini.lmdb

#### network structures
# netSR:
#   which_network: RRDBNet
#   setting:
#     in_nc: 3
#     out_nc: 3
#     nf: 64
#     nb: 23
#     upscale: 4
#   pretrain:
#     path: ../../../checkpoints/ESRGAN/RRDB_PSNR_x4.pth
#     strict_load: true

networks:
  netSR:
    which_network: EDSR
    setting:
      nf: 64
      nb: 16
      res_scale: 1
      upscale: 4
    pretrain:
      path: ../../../checkpoints/EDSR/edsr_baseline_x4-new.pt
      strict_load: true

  # netD3:
  #   which_network: PatchGANDiscriminator
  #   setting:
  #     in_c: 3
  #     nf: 64
  #     nb: 3
  #     stride: 2
  #   pretrain:
  #     path: ~
  #     strict_load: true
    
  #### network structures  
  netG1:
    which_network: Translator
    setting:
      nf: 64
      nb: 8
      scale: 1
    pretrain:
      path: log/Trans2017Track1/models/190000_netG1.pth
      strict_load: true

  netD1:
    which_network: PatchGANDiscriminator
    setting:
      in_c: 3
      nf: 64
      nb: 3
      stride: 2
    pretrain:
      path: log/Trans2017Track1/models/190000_netD1.pth
      strict_load: true

  netG2:
    which_network: Translator
    setting:
      nf: 64
      nb: 8
      scale: 1
    pretrain:
      path: log/Trans2017Track1/models/190000_netG2.pth
      strict_load: true

  netD2:
    which_network: PatchGANDiscriminator
    setting:
      in_c: 3
      nf: 64
      nb: 3
      stride: 2
    pretrain:
      path: log/Trans2017Track1/models/190000_netD2.pth
      strict_load: true

#### training settings: learning rate scheme, loss
train:
  resume_state: ~
  max_grad_norm: 50.0
  buffer_size: 16

  losses:
    # sr_adv:
    #   type: GANLoss
    #   gan_type: lsgan
    #   real_label_val: 1.0
    #   fake_label_val: 0.0
    #   weight: !!float 0.0

    sr_pix_trans: 
      type: MSELoss
      weight: 1000.0
    
    sr_pix:
      type: MSELoss
      weight: 1.0

    # sr_percep:
    #   type: PerceptualLoss
    #   layer_weights:
    #     'conv5_4': 1  # before relu
    #   vgg_type: vgg19
    #   use_input_norm: true
    #   range_norm: false
    #   perceptual_weight: 1.0
    #   style_weight: 0
    #   criterion: l1
    #   weight: !!float 0.0

    g1_d1_adv:
      type: GANLoss
      gan_type: lsgan
      real_label_val: 1.0
      fake_label_val: 0.0
      weight: !!float 1.0

    g2_d2_adv:
      type: GANLoss
      gan_type: lsgan
      real_label_val: 1.0
      fake_label_val: 0.0
      weight: !!float 1.0
    
    g1_idt:
      type: L1Loss
      weight: 5
    
    g2_idt:
      type: L1Loss
      weight: 5

    g1g2_cycle:
      type: L1Loss
      weight: 10.0

    g2g1_cycle: 
      type: L1Loss
      weight: 10.0

  optimizers:
    netSR:
      type: Adam
      lr: !!float 1e-4
      betas: [0.5, 0.999]
    netG1:
      type: Adam
      lr: !!float 2e-4
      betas: [0.5, 0.999]
    netG2:
      type: Adam
      lr: !!float 2e-4
      betas: [0.5, 0.999]
    netD1:
      type: Adam
      lr: !!float 2e-4
      betas: [0.5, 0.999]
    netD2:
      type: Adam
      lr: !!float 2e-4
      betas: [0.5, 0.999]
    # netD3:
    #   type: Adam
    #   lr: !!float 1e-4
    #   betas: [0.5, 0.999]
  
  niter: 200000
  warmup_iter: -1  # no warm up

  scheduler:
    type: MultiStepLR
    milestones: [50000, 100000, 150000]
    gamma: 0.5

  manual_seed: 0
  val_freq: !!float 5e3

#### logger
logger:
  print_freq: 100
  save_checkpoint_freq: !!float 5e3
