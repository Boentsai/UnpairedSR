#### general settings
name: 2017Track1
use_tb_logger: false
model: PseudoSupModel
scale: 4
gpu_ids: [7]
metrics: [psnr, ssim, lpips]

#### datasets
datasets:
  train:
    name: DIV2K
    mode: PairedRefDataset
    data_type: lmdb
    color: RGB
    ratios: [1, 1]

    dataroot_ref_tgt: /mnt/hdd/lzx/SRDatasets/DIV2K_train/HR/x4_half.lmdb
    dataroot_ref_src: /mnt/hdd/lzx/SRDatasets/DIV2K_train/BicLR/x4_half.lmdb
    dataroot_src: /mnt/hdd/lzx/SRDatasets/NTIRE2017/train_LR/x4_half.lmdb

    use_shuffle: true
    n_workers: 8  # per GPU
    batch_size: 32
    tgt_size: 128
    src_size: 32
    use_flip: true
    use_rot: true

  val:
    name: 2017Track1_mini
    mode: PairedDataset
    data_type: lmdb
    color: RGB

    dataroot_src: /mnt/hdd/lzx/SRDatasets/NTIRE2017/valid_LR/x4_mini.lmdb
    dataroot_tgt: /mnt/hdd/lzx/SRDatasets/DIV2K_valid/HR/x4_mini.lmdb


#### network structures
networks:
  netSR:
    which_network: EDSR
    setting:
      nf: 64
      nb: 16
      res_scale: 1
      upscale: 4
    pretrain: 
      path: ../../../checkpoints/EDSR/edsr_baseline_x4-new.pt
      strict_load: true

  netD3:
    which_network: PatchGANDiscriminator
    setting:
      in_c: 3
      nf: 64
      nb: 3
      stride: 2
    pretrain:
      path: ~
      strict_load: true
    
  #### network structures  
  netG1:
    which_network: Translator
    setting:
      nf: 64
      nb: 8
      zero_tail: true
      scale: 1
    pretrain: 
      path: ~
      strict_load: true

  netD1:
    which_network: PatchGANDiscriminator
    setting:
      in_c: 3
      nf: 64
      nb: 3
      stride: 2
    pretrain: 
      path: ~
      strict_load: true

  netG2:
    which_network: Translator
    setting:
      nf: 64
      nb: 16
      zero_tail: true
      scale: 1
    pretrain: 
      path: ~
      strict_load: true
    
  netD2:
    which_network: PatchGANDiscriminator
    setting:
      in_c: 3
      nf: 64
      nb: 3
      stride: 2
    pretrain: 
      path: ~
      strict_load: true

#### training settings: learning rate scheme, loss
train:
  resume_state: ~

  losses:
    sr_pix:
      type: L1Loss
      weight: 1

    srd3_adv:
      type: GANLoss
      gan_type: lsgan
      real_label_val: 1.0
      fake_label_val: 0.0
      weight: !!float 0.1

    g1d1_adv:
      type: GANLoss
      gan_type: lsgan
      real_label_val: 1.0
      fake_label_val: 0.0
      weight: !!float 1.0
      
    g2d2_adv:
      type: GANLoss
      gan_type: lsgan
      real_label_val: 1.0
      fake_label_val: 0.0
      weight: !!float 1.0
    
    g1g2_cycle:
      type: L1Loss
      weight: 1.0
    
    g2g1_cycle:
      type: L1Loss
      weight: 1.0
    
    g1_idt:
      type: L1Loss
      weight: 1
    
    g2_idt:
      type: L1Loss
      weight: 1

  optimizers:
    netSR:
      type: Adam
      lr: !!float 1e-4
      betas: [0.9, 0.999]
    netG1:
      type: Adam
      lr: !!float 1e-4
      betas: [0.5, 0.999]
    netG2:
      type: Adam
      lr: !!float 1e-4
      betas: [0.5, 0.999]
    netD1:
      type: Adam
      lr: !!float 1e-4
      betas: [0.5, 0.999]
    netD2:
      type: Adam
      lr: !!float 1e-4
      betas: [0.5, 0.999]
    netD3:
      type: Adam
      lr: !!float 1e-4
      betas: [0.5, 0.999]
  
  niter: 300000
  warmup_iter: -1  # no warm up

  scheduler:
    type: MultiStepLR
    milestones: [100000, 180000, 240000]
    gamma: 0.5

  manual_seed: 0
  val_freq: !!float 5e3

#### logger
logger:
  print_freq: 100
  save_checkpoint_freq: !!float 5e3
